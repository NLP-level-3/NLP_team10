# '21. 10. 26 NLP 10조 피어세션 정리'

## retriever 뜯기 

Dense Embedding을 만들어서 얼마나 맞추는 지 봤는데, 아직 뜯어보는 중이라 기록하면서 만들지 않아 어떻게 설정했는지 기억은 안나지만. 30%는 찍었다. 많이 부족하다고 판단하여 처음에 로베르타로 했을때, sparse Embedding 성능을 보려고 따로 만들어서 확인 중이다. 이게 3프로가 나왔었는데, 리트리버에 계속 집중하고자 한다. 그래서 리트리버를 계속 파는 중이다.

리트리버쪽을 집중해서 보는게 성능 향상에 도움이 될 것으로 보인다.

Retriever

- 학습모델
    - multilingual-model
    1.  
        - epoch : [10, 30]
        - weight decay : 0.01
        - learning rate : 1e-5
        - 정확도 0.30
    2. - epoch : 5
        - weight decay : 0.01
        - learning rate : 5e-5
        - label smoothing factor : 0.1
        - gradient accumulate step : 3
        - 정확도 0.004
    3.  - epoch : 5
        - weight decay : 0.01
        - learning rate : 1e-5
        - label smoothing factor : 0.1
        - 정확도 0.158

epoch를 늘렸더니 성능이 좋아진 것같다. 따라서 100번 돌려보려고한다. sparse는 해야될지 안해야될지 생각해봐야겠다.

Q : 데이터셋 가져올때, 이미 토크나이즈가 된 상태이냐 ? <br>
A : 토크나이즈를 따로 해준다.





        


## 베이스라인 코드

오늘까지는 특별한 내용은 없다. 

Q : 베이스라인 코드는 주로 어떤 식으로 확인하는가요 ? <br>
A : 에러가 나는 곳을 보면 보통 huggingface라서 다 찾아볼 수 밖에 없었다. torch source까지 들어가서 봐야지 해결하는 오류가 몇개 있다. 에러난 곳마다 프린트 찍어보면서 찾아보는게 가장 배우기 좋다.

## retriever 구현

성능이 너무 안나와서 깃에는 올리진 않았다. 어디서 문제가 나는지 확인을 해야하는데 일일히 찾아보는 수 밖에 없어서 찾기 어려운 상태이다. 문제 해결하려고 노력중입니다. 여러가지 문제발생.
