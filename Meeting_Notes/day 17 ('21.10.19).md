# '21. 10. 19 NLP 10조 피어세션 정리'

## 앙상블 기법 (1기 노트 참고)
여러 모델들을 쌓아서 하드보팅으로 앙상블하면 성능이 매우 좋아졌음 (EM 지표 특성 상 소프트보다 하드가 잘 나왔다고 함)

## Retrieval 전처리 후 정확도 0이 나오는 문제
전처리 안 한 vanilla 데이터로도 0이 나옴 -> baseline 코드 그대로 모델만 BERT-multilingual에서 KLUE/RoBERTa 로 바꿨더니 정확도가 오히려 낮아짐

## 실행 코드 python train.py로 간략화하기
코드 분리해서 parser로 파일 읽어오기로 완료

## WandB 활용
training arguments를 넘겨주어 로그 기록하게 만들기