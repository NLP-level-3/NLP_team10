
# '21. 10. 05 NLP 10조 피어세션 정리'

### 오늘의 BEST RESULT
총 제출횟수 : 22 <br>
Baseline Model -> 9th / 19<br> (**!SILBER TIER!**)
micro F1 : 63.389 -> 71.854 (+8.465) <br>
auprc : 69.895 -> 69.292 (-0.603)<br>

## 내용

### 데이터 증강
- (김범찬; 데이터 증강)RE 모델 전에 NER 모델을 추가하여, 데이터 증강을 시도하였다. 
  - NER 모델은 SKT/KoBERT 모델을 사용했고, 현재 NER 모델에 넣을 data preprocessing해주는 중

- (최수홍; 데이터 증강) EDA를 (easy data augmentation)을 실험해보았는데, 한국어 특성상 문장의 구조가 흐트러질 수가 있다. 따라서 문장부호를 랜덤으로 추가하는 것으로 실험해보고 있다. (**수홍님이 추가수정**)

- (고지호; 데이터 증강) entity 앞 뒤로 subject, object token을 추가한 후, Selenium + Papago를 통해 한국어 문장을 일본어 문장으로 바꾼 후에, 다시 한국어로 바꾸는 것으로 데이터 증강을 하는 중.
  - 24 개의 멀티 스레드를 통해 전부 처리 완료했음.
  - 모든 언어 중에, 일본어의 번역 성능이 가장 뛰어났기 때문에 일본어를 사용.

- (고지호; 데이터 증강) subject entity와 object entity 간의 관계 중 다른 관계를 유추할 수 있을 때, sub, obj, relation을 변형하여 데이터를 늘렸다 (to approx. 90000).
  - 그러나 'no_relation'이 너무 많기 때문에 bias 문제는 해결하지 못했다.

> 경향성을 해결해줄 수 있는 접근법이 필요하다.

### 전처리

- (심현덕; 전처리) 특수문자를 전부 제거하고, 단어의 앞뒤로 subject, object 토큰을 넣어서 학습해보았다.
  - 전부 No_relation으로 결과를 도출해서 방법이 잘못된 거 같다. 확인을 좀 해야할듯...
  - (김민성) 나도 같은 방법으로 학습을 해봤는데 같은 결과가 나왔다. 접근방법이 애초에 잘못된듯.


1. subj, obj 토큰을 따로 넣지는 않고, sep 토큰으로 분류해서 subj, obj word를 sentence 뒤에 concate했다.
-> 실패

2. sub, obj로 나누지 말고 entitiy token으로 나눴다.
-> 실패

3. word를 masked하고 sentence 뒤에 concate했다
-> 실패

4. sentence, sub word, type, obj word, type 을 sep 토큰으로 나눴다.
-> 나름 쓸만함

5. 불용어(entitiy가 아닌 단어)99개를 special token으로 추가
->  F1 score가 1~2 상승함

### 모델

- (김민성; 모델)
bert multilingual model은 vocab이 20만 개가 넘어가는데, 적은 epoch으로는 제대로 학습이 안되는 것 같다.

- (김민성; 모델) Label smoothing도 넣어봤는데 오히려 성능이 떨어지는 경향이 있었다.

