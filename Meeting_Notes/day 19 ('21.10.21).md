# '21. 10. 21 NLP 10조 피어세션 정리'

## Dense Retriever이 문제 해결
- typo를 찾아서 수정
- 코드 자체는 다른 코드들과 상이하지 않음
- epoch를 늘려 더 fitting 시도

## 앙상블에서의 dense layer 활용
예를 들어, 문제를 토큰으로 임베딩하여 앙상블모델이 읽어들이도록 한 후, 문제에 따라 앙상블 할 결과모델들의 예측값에 가중치를 각각 다르게 두어 앙상블을 할 수 있도록 앙상블모델을 학습시킴

앙상블모델의 경우 question과 각 결과모델들의 답들을 SEP으로 연결시켜 classification을 하는 것도 나쁘지 않을 듯

## 1d-Conv를 이용한 분석
RoBERTa 등을 이용해 embedding 한 벡터를 input으로 넣어 1d Convolution Filter를 거쳐 정보를 뽑아냄, 이후 classification layer를 통과해 logit을 계산하여 start idx와 end idx를 도출해내는 아이디어

## Retriever 모델의 Validation Metric
결과 text와 ground truth의 similarity를 계산해 나온 결과값들의 평균을 이용하는 방법은 괜찮을까?

Facebook 에서는 EM을 사용했고, F1 score를 사용하는 방법도 있음.

similarity를 이용하는 경우에는 절대적인 기준이 없는 내적을 이용하기보다 cosine similarity를 이용해 일종의 정규화를 시키는 것이 더 좋을듯

## RoBERTa에 LSTM 두개 올린 모델
잘 돌아가긴 하는데 early stopping을 하기 위해서는 evaluation set이 필요해서 evaluation set의 전처리를 train set과 동일하도록 처리하여 다시 돌리는 중

9팀 코드 참고해서 돌리지만 구조를 살짝 바꾸고 파라미터를 바꿔서 mrc에 적합하도록 수정