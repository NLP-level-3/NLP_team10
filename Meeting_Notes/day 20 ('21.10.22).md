# '21. 10. 22 NLP 10조 피어세션 정리'

## dense retriever

retriever validation 과정에서 positive sample 끼리의 cosine similarlity와 negative sample의 cosine similiarty를 구해서 둘을 비교함.

- retriever의 objective는 cosine similarity of positive sample은 높이고, that of negative ones는 최대한 낮추는 것.
- 즉, 두 metric 간의 거리를 최대화 시키는 것이 모델의 목적
- 그러나, 두 metric이 같이 올라가는 방향으로 학습이 됨
    - positive sample의 cosine similarity가 증가하면, negative sample의 cosine similarity도 같이 증가하고, 감소하면 같이 감소한다.
    - `torch.nn.CrossEntropyLoss` 함수 쓰지 말고 DPR 논문에 나온 Loss function을 직접 구현해서 써볼까...?
    - DPR 논문 제대로 읽고 한 번 해보자...📃

## dvc를 이용한 데이터 버전 관리
git과 dvc을 pull해서 google drive의 파일을 가져올 수 있도록 하는 방법

버전 별로 가져오고 싶은 파일을 가져올 수 있음

git은 data version을 관리, dvc는 원본 데이터를 분리하여 원격 저장소(google drive)에 저장

version v1.1 (초기 상태의 데이터)

## early stopping을 위한 validation dataset 수정
validation 데이터를 수정하면 preprocessing.py 파일에서 오류가 발생함

베이스라인 코드 + 허깅페이스 소스까지 다 뒤져보면서 맞게 수정해서 겨우 작동시킴

## RoBERTa 위에 LSTM을 쌓는 모델
참고한 모델을 수정하여 LSTM 2개에 각각 RoBerTa output을 입력시킴(논문 아키텍쳐 구현)

결과는 나쁘지 않을 듯

## 회고

### 잘 된점

To-do list 작성을 착실하게 하고있다.
- 다른사람들은 무엇을 하는지 잘 몰랐는데, To-do list를 통해 개개인이 어떤 작업을 하고 있는지 쉽게 확인할 수 있어서 좋다ㅎㅎ :)

### 아쉬운 점
베이스라인 해석이 늦었다 -> 커스텀할 수 있는 시간이 줄었음

진행사항이 조금 느린것 같다
- Retriever를 거의 2주 동안 하고 있는데, 뭔가 얻은 게 없는듯 😭
- Retriever 같이 할 사람 있었으면 좋겠다.

두 달간 병원🚑에 뺏기던 시간이 이제 거의 없을 예정!! 학습과 코딩에 집중할 수 있습니다

강의를 습득하는데 조금 어려움이 있어서 복습하면서 정리하는데 시간을 너무 많이 써서 아쉽습니다.

### 개선하면 좋을 점
주말에도 시간 투자해서 모델 성능을 최대한 끌어올려보자!!
