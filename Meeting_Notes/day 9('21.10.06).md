
# '21. 10. 06 NLP 10조 피어세션 정리'

### 오늘의 BEST RESULT
총 제출횟수 : 29 <br>
Baseline Model -> 5th / 19<br> (**!SILBER TIER!**) :)
micro F1 : 71.854 -> 73.248  (+1.394) <br>
auprc : 69.292 -> 69.292 (+1.817)<br>

## 내용

김범찬
- Subject entity와 Object entity 내의 단어를 같은 type을 가진 다른 단어로 치환하여 데이터 증강 시도 중
  - 딱 entitiy 위치만 치환이 되기 때문에, 같은 글자지만 다른 위치에 있으면 치환이 안 되기 때문에 이거 수정해야 함.

김민성
- 문장 내에 `@`, `*`, `#` 등 아무런 의미가 없는 글자들을 추가해봤다.
- BERT 모델 뒤에 GRU Linear를 추가하여 모델 학습 중에 있다. (Bi-directional은 메모리를 너무 먹음)

## 팀회고

김정현 :

김범찬 : 데이터 증강 너무 오래했다... 오늘 결과가 어덯게 나오든 꼭 끝내고 모델 돌릴 수 있도록 하겠습니다!

심현덕 :

김민성 :

고지호 :

최수홍 :
